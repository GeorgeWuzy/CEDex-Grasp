# Official Repository of CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations

**Authors**: Zhiyuan Wu<sup>1</sup>, Rolandos Alexandros Potamias<sup>2</sup>, Xuyang Zhang<sup>1</sup>, Zhongqun Zhang<sup>3</sup>, Jiankang Deng<sup>2</sup>, Shan Luo<sup>1</sup>  
<sup>1</sup> King's College London | <sup>2</sup> Imperial College London | <sup>3</sup> Nankai University

## Project Links
- [Arxiv Paper](https://arxiv.org/abs/2509.24661)
- [PDF Version](https://arxiv.org/pdf/2509.24661)
- [Project Website](https://georgewuzy.github.io/cedex-website/)

## Overview

In this paper, we propose **CEDex**, a novel cross-embodiment dexterous grasp synthesis method that bridges human grasping kinematics and robot kinematics by aligning robot kinematic models with generated human-like contact representations. Using CEDex, we construct the largest cross-embodiment grasp dataset to date, comprising **500K objects** across four gripper types with **20M total grasps**.

![Pipeline](assets/pipeline.gif)

## Dataset Release

We have currently released the **real-world object set** grasp data. You can find a visual representation of this dataset below: 

![Real-World Objects](assets/rw_objects.gif)

We will soon release a larger scale of **synthesis objects** grasp data, as shown in the image below. Please stay tuned for updates!

![Simulation Objects](assets/sim_objects.gif)

The code for data generation will be published after the acceptance of the paper.